% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/OptimizerSumoHB.R, R/TunerSumoHB.R
\name{OptimizerSumoHB}
\alias{OptimizerSumoHB}
\alias{TunerSumoHB}
\title{Surrogate Model Assisted Hyperband Optimizer}
\description{
Perform Surrogate Model Assisted Hyperband Optimization.

Given a population size \code{mu}, a fraction of surviving individuals \code{survival_fraction}, a number of generations \code{n} and a fidelity progression \code{F0}, \code{F1}, ..., \code{Fn},
the algorithm works as follows:
\enumerate{
\item Sample an initial design of size \code{mu} at fidelity \code{F0}
\item Kill individuals that are not in the top \code{survival_fraction} part of individuals, by performance
\item Generate new individuals using either random sampling, or \strong{surrogate model filtering}, until \code{mu} alive individuals are present again.
\item Evaluate all alive individuals at fidelity \verb{F\{generation\}}
\item Jump to 2., until termination, possibly because \code{n} generations are reached.
}

The number of generations \code{n} is determined from the \code{\link[bbotk:OptimInstance]{OptimInstance}}'s \code{\link[bbotk:Terminator]{Terminator}} object, see \strong{Terminating}
below.

The \strong{fidelity progression} uses a specially designated "budget" parameter of the \code{\link[bbotk:OptimInstance]{OptimInstance}}, which must have a \code{"budget"} tag.
The lower limit of the budget parameter is used as \code{F0}. The upper limit is used as \code{Fn}. The budget is evaluated at equally spaced values in generations \verb{0..n},
so \code{F1} - \code{F0} = \code{F2} - \code{F1} etc. In many cases it is desirable to have a multiplicative progression of "difficulty" of the problem. In this case, it is
recommended to use a budget parameter with exponential "trafo", or one with \code{logscale = TRUE} (see example).
}
\section{Terminating}{

\code{\link{TerminatorGenerations}} is used to determine the number of fidelity refinements to be performed. Therefore, the  \code{\link[bbotk:OptimInstance]{OptimInstance}}
being optimized must contain a \code{\link{TerminatorGenerations}}. Either directly (\code{inst$terminator}), or indirectly through a
\code{\link[bbotk:mlr_terminators_combo]{bbotk::TerminatorCombo}} with \verb{$any} set to \code{TRUE} (recursive \code{\link[bbotk:mlr_terminators_combo]{TerminatorCombo}} may also be used). The
number of generations is determined from the given \code{\link[bbotk:Terminator]{Terminator}} object and the number of fidelity refinements
is planned according to this number. Other terminators may be present in a \code{\link[bbotk:mlr_terminators_combo]{TerminatorCombo}} that may
lead to finishing the tuning process earlier.

TODO: what does generations == 0 mean?
}

\section{Surrogate Model Filtering}{

A \emph{surrogate model} is a regression model, based on an \code{\link[mlr3:Learner]{mlr3::Learner}}, which predicts the approximate performance of newly sampled configurations
given the empirical performance of already evaluated configurations. If the optional \code{surrogate_learner} construction argument is given to \code{SumoHB},
then the surrogate model is used to propose points that have, according to the surrogate model, a relatively high chance of performing well.

Given the number \code{lambda} of of new individuals to sample, surrogate model filtering proceeds as follows:
\enumerate{
\item Sample \code{filter_rate_first} configurations, predict their expected performance using the surrogate model, and put them
into a pool \code{P} of configurations to consider.
\item Take the individual that is optimal according to predicted performance, remove it from \code{P} and add it to solution set \code{S}.
\item If the number of solutions in \code{S} equals \code{lambda}, quit.
\item Sample \code{filter_rate_per_sample} configurations, predict their expected performance using the surrogate model, and add them to \code{P}.
\item Jump to 2.
}

(The algorithm presented here is optimized for clarity; the actual implementation does all the surrogate model prediction in one go, but is functionally
equivalent).

The \code{filter_rate_first} and \code{filter_rate_per_sample} configuration parameters of this algorithm determine how agressively the surrogate model is used to
filter out sampled configurations. If the filtering is agressive (\code{filter_rate_first} is large), then more "exploitation" at the cost of "exploration" is performed.
When \code{filter_rate_first} is small but \code{filter_rate_per_sample} is large, then successive individuals are filtered successively more agressively, potentially
leading to a tradeoff between "exploration" and "exploitation".

When \code{filter_rate_per_sample} is set to 0, then the method is equivalent to sampling the top \code{lambda} individuals from \code{filter_rate_first}
sampled ones. When \code{filter_rate_per_sample} is 1 and \code{filter_rate_first} is 0, then the method is equivalent to random sampling.

\code{filter_rate_first} and \code{filter_rate_per_sample} may be fractional; the total number of individuals to select from when selecting \code{i}
individuals is always round(\code{filter_rate_first} + (\code{filter_rate_per_sample} - 1) * (\code{i} - 1)). However, \code{filter_rate_first} must
be at least 1, and \code{filter_rate_first} + \code{filter_rate_per_sample} * (\code{lambda} - 1) must be at least \code{lambda}.
}

\section{Configuration Parameters}{

\code{OptimizerSumoHB}'s configuration parameters are the hyperparameters of the \code{surrogate_learner} \code{\link[mlr3:Learner]{Learner}}, as well as:
\itemize{
\item \code{mu} :: \code{integer(1)}\cr
Population size: Number of individuals that are sampled in the beginning, and which are re-evaluated in each fidelity step. Initialized to 2.
\item \code{survival_fraction} :: \code{numeric(1)}\cr
Fraction of the population that survives at each fidelity step. The number of newly sampled individuals is (1 - \code{survival_fraction}) * \code{mu}.
\item \code{filter_rate_first} :: \code{numeric(1)}\cr
Only present when the \code{surrogate_learner} construction argument is not \code{NULL}.
\code{filter_rate_first} parameter of the surrogate model filtering algorithm, see the corresponding section. Initialized to 1. Together with the
default of \code{filter_rate_per_sample}, this is equivalent to random sampling new individuals.
\item \code{filter_rate_per_sample} :: \code{numeric(1)}\cr
Only present when \code{surrogate_learner} construction argument is not \code{NULL}.
\code{filter_rate_per_sample} parameter of the surrogate model filtering algorithm, see the corresponding section.
Initialized to 1. Together with the default of \code{filter_rate_per_sample}, this is equivalent to random sampling new individuals.
\item \code{sampling} :: \code{function}\cr
Function that generates the initial population, as well as new individuals to be filtered from, as a \code{\link[paradox:Design]{Design}} object. The function must have
arguments \code{param_set} and \code{n} and function like \code{\link[paradox:generate_design_random]{paradox::generate_design_random}} or \code{\link[paradox:generate_design_lhs]{paradox::generate_design_lhs}}.
This is equivalent to the \code{initializer} parameter of \code{\link[=mies_init_population]{mies_init_population()}}, see there for more information. Initialized to
\code{\link[paradox:generate_design_random]{generate_design_random()}}.
}
}

\examples{
\donttest{
lgr::threshold("warn")

# Define the objective to optimize
objective <- ObjectiveRFun$new(
  fun = function(xs) {
    z <- exp(-xs$x^2 - xs$y^2) + 2 * exp(-(2 - xs$x)^2 - (2 - xs$y)^2)
    list(Obj = z)
  },
  domain = ps(x = p_dbl(-2, 4), y = p_dbl(-2, 4)),
  codomain = ps(Obj = p_dbl(tags = "maximize"))
)

# Get a new OptimInstance
oi <- OptimInstanceSingleCrit$new(objective,
  terminator = trm("evals", n_evals = 100)
)

# TODO
# sumohb_opt <- # TODO
# sumohb_opt$optimize performs SumoHB optimization and returns the optimum
# sumohb_opt$optimize(oi)

#####
# Optimizing a Machine Learning Method
#####

# Note that this is a short example, aiming at clarity and short runtime.
# The settings are not optimal for hyperparameter tuning. The resampling
# in particular should not be "holdout" for small datasets where this gives
# a very noisy estimate of performance.

library("mlr3")
library("mlr3tuning")

# The Learner to optimize
learner = lrn("classif.rpart")

# The hyperparameters to optimize
learner$param_set$values[c("cp", "maxdepth")] = list(to_tune())

# Get a TuningInstance
ti = TuningInstanceSingleCrit$new(
  task = tsk("iris"),
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.acc"),
  terminator = trm("gens", generations = 10)
)

# sumohb_tune <- # TODO
# sumohb_tune$optimize performs SumoHB optimization and returns the optimum
# sumohb_tune$optimize(ti)
}
}
\seealso{
Other optimizers: 
\code{\link{OptimizerMies}}
}
\concept{optimizers}
\section{Super class}{
\code{\link[bbotk:Optimizer]{bbotk::Optimizer}} -> \code{OptimizerSumoHB}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{surrogate_learner}}{(\code{\link[mlr3:LearnerRegr]{mlr3::LearnerRegr}} | \code{NULL})\cr
Regression learner for the surrogate model filtering algorithm.}

\item{\code{param_set}}{(\code{\link[paradox:ParamSet]{ParamSet}})\cr
Configuration parameters of the optimization algorithm.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{OptimizerSumoHB$new()}}
\item \href{#method-clone}{\code{OptimizerSumoHB$clone()}}
}
}
\if{html}{
\out{<details open ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="bbotk" data-topic="Optimizer" data-id="format">}\href{../../bbotk/html/Optimizer.html#method-format}{\code{bbotk::Optimizer$format()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="bbotk" data-topic="Optimizer" data-id="optimize">}\href{../../bbotk/html/Optimizer.html#method-optimize}{\code{bbotk::Optimizer$optimize()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="bbotk" data-topic="Optimizer" data-id="print">}\href{../../bbotk/html/Optimizer.html#method-print}{\code{bbotk::Optimizer$print()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Initialize the 'OptimizerSumoHB' object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{OptimizerSumoHB$new(surrogate_learner = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{surrogate_learner}}{(\code{\link[mlr3:LearnerRegr]{mlr3::LearnerRegr}} | \code{NULL})\cr
Regression learner for the surrogate model filtering algorithm. May be \code{NULL}, in which case no surrogate model is used and individuals are sampled randomly.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{OptimizerSumoHB$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
\section{Super classes}{
\code{\link[mlr3tuning:Tuner]{mlr3tuning::Tuner}} -> \code{\link[mlr3tuning:TunerFromOptimizer]{mlr3tuning::TunerFromOptimizer}} -> \code{TunerSumoHB}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{TunerSumoHB$new()}}
\item \href{#method-clone}{\code{TunerSumoHB$clone()}}
}
}
\if{html}{
\out{<details open ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="format">}\href{../../mlr3tuning/html/Tuner.html#method-format}{\code{mlr3tuning::Tuner$format()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="print">}\href{../../mlr3tuning/html/Tuner.html#method-print}{\code{mlr3tuning::Tuner$print()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3tuning" data-topic="TunerFromOptimizer" data-id="optimize">}\href{../../mlr3tuning/html/TunerFromOptimizer.html#method-optimize}{\code{mlr3tuning::TunerFromOptimizer$optimize()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Initialize the \code{TunerSumoHB} object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TunerSumoHB$new(surrogate_learner = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{surrogate_learner}}{(\code{\link[mlr3:LearnerRegr]{mlr3::LearnerRegr}} | \code{NULL})}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TunerSumoHB$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
